|항목|내용|
|---|---|
|프로젝트명|멀티 모달 기반 질병 예측 인공지능 모델 및 일반인들에게 직관적으로 설명 가능성 연구|
|프로젝트 키워드|데이터 전처리(의료), 멀티 모달, 인공지능 모델, deep learning|
|트랙|연구 트랙|
|프로젝트멤버|김문경(2376029), 박선영(2376100), 안서연(2276177)|
|팀지도교수|황의원 교수님|
|무엇을 만들고자 하는가|본 프로젝트는 멀티모달 기반 질병 판단 인공지능 모델을 개발하는 것을 목표로 합니다.  
이 모델은 의료 영상, 생체 신호, 임상 기록 등 다양한 데이터를 통합적으로 분석하여 질병을 진단하는 과정에서 환자가 자신의 건강 상태를 직관적으로 이해할 수 있도록 돕습니다. 의사에게는 해당 모델이 제시하는 설명가능한 근거(예: 특정 영상 부위의 이상, 주요 임상 지표, 데이터 간 상관관계)를 바탕으로 보다 정확하고 신뢰성 있는 진단을 내릴 수 있는 지원 도구로 활용된다. 환자에게는 단순한 결과 제시가 아닌, 왜 이러한 진단이 내려졌는지를 시각적·설명적 형태로 제공하여 스스로 질병을 이해하고 관리할 수 있도록 돕는다. 이를 통해 의료진과 환자 간의 의사소통이 원활해지고, 환자는 치료 과정에 보다 능동적으로 참여할 수 있으며, 결과적으로 임상적 신뢰성과 환자 경험을 동시에 향상시키는 것을 목표로 한다.|
|고객|의료기관, 의사, 환자(일반인)  페르소나
* 김지현(42세, 직장인(사무직), 여성)  
- 최근 건강검진에서 폐 관련 이상 소견을 발견함.  
- 전문의에게 질병에 대한 소견을 듣긴 했지만, 말로만 들으니 이해가 부족하고 추상적이라 느낌.  
- 자신의 질병에 대한 시각적인 확인과 설명 가능한 근거를 직관적으로 확인하고 싶음. |
|Pain Point|의료 진단 분야에서 인공지능의 활용은 빠르게 확대되고 있지만, 기존 딥러닝 기반 블랙박스 모델은 단순히 결과만 제시할 뿐 왜 그런 결론에 도달했는지에 대한 근거를 제공하지 못해 투명성과 신뢰성에 한계가 있습니다. 이는 의료진이 결과를 임상 의사결정에 적극 반영하기 어렵게 만들고, 환자와 보호자에게도 불안감을 줍니다. 또한 설명이 불가능한 모델은 AI가 잘못된 패턴을 학습했는지 혹은 특정 집단에 불리한 데이터 편향을 가지고 있는지를 파악할 수 없다는 문제를 안고 있습니다. 따라서 설명 가능한 인공지능(XAI)은 단순한 예측 성능을 넘어, 투명성과 해석 가능성을 보장하고 의사-환자-모델 간 신뢰를 구축하는 데 필수적이며, 특히 영상·생체신호·임상기록과 같은 멀티모달 데이터를 활용할 경우 각 데이터가 최종 진단에 어떻게 기여했는지를 드러내는 것이 중요합니다.|
|사용할 소프트웨어 패키지의 명칭과 핵심기능/용도, 사용시나리오||
|사용할 소프트웨어 패키지의 명칭과 URL||
|팀그라운드룰||
|최종수정일|2025.09.09|
